{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì»¤ìŠ¤í…€ Document Loader ì‘ì„± ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê°œìš”\n",
    "\n",
    "LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ PDF ê°™ì€ íŒŒì¼ ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  LLMì´ í™œìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤. `ë­ì²´ì¸(LangChain)`ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¶”ì¶œëœ `í…ìŠ¤íŠ¸(page_content)`ë¥¼ `ë©”íƒ€ë°ì´í„°(metadata)`ì™€ í•¨ê»˜ ìº¡ìŠí™”í•˜ëŠ” `Document` ê°ì²´(ì‘ê°€ì˜ ì´ë¦„ì´ë‚˜ ê²Œì‹œ ë‚ ì§œ ë“± ë¬¸ì„œì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ê°€ í¬í•¨ëœ ì‚¬ì „)ë¥¼ ìƒì„±í•œë‹¤.\n",
    "\n",
    "`Document` ê°ì²´ëŠ” LLMì— ì…ë ¥ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜ëœë‹¤. ê·¸ë¦¬ê³  LLMì€ ì´ `Document` ë‚´ì˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ì‘ë‹µ(ì˜ˆ: ë¬¸ì„œ ìš”ì•½)ì„ ìƒì„±í•œë‹¤. `Document` ê°ì²´ëŠ” ì¦‰ì‹œ ì‚¬ìš©í•˜ê±°ë‚˜ í–¥í›„ ê²€ìƒ‰ì„ ìœ„í•´ `ë²¡í„° ì €ì¥ì†Œ(vectorstore)`ì— ì €ì¥ëœë‹¤.\n",
    "\n",
    "ë¬¸ì„œ ë¡œë”©ì˜ ì£¼ìš” ì¶”ìƒí™”ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "- Document : `text`ì™€ `metadata`ë¥¼ ê°€ì§„ë‹¤.\n",
    "- BaseLoader : ì›ë³¸ ë°ì´í„°ë¥¼ `Document` ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ì‹œí‚¨ë‹¤.\n",
    "- Blob : íŒŒì¼ ë˜ëŠ” ë©”ëª¨ë¦¬ì— ì¡´ì¬í•˜ëŠ” ì´ì§„ ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "- BaseBlobParser : `Blob`ì„ íŒŒì‹±í•˜ì—¬ ë¬¸ì„œ ê°ì²´ë¥¼ ìƒì„±í•œë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” `ì‚¬ìš©ì ì§€ì • ë¬¸ì„œ ë¡œë”©(custom document loading)`ê³¼ `íŒŒì¼ êµ¬ë¬¸ ë¶„ì„ ë¡œì§(file parsing logic)`ì„ ì‘ì„±í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•œë‹¤.\n",
    "\n",
    "1. `BaseLoader` ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œ `í‘œì¤€ ë¬¸ì„œ ë¡œë”(standard document loader)`ë¥¼ ë§Œë“ ë‹¤.\n",
    "2. `BaseBlobParser`ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì„œë¥¼ ìƒì„±í•˜ê³  `Blob` ë° `BlobLoaders`ì™€ í•¨ê»˜ ì‚¬ìš©í•œë‹¤. ì´ ê¸°ëŠ¥ì€ ì£¼ë¡œ íŒŒì¼ ì‘ì—… ì‹œ ìœ ìš©í•˜ë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í‘œì¤€ ë¬¸ì„œ ë¡œë”\n",
    "`ë¬¸ì„œ ë¡œë”(document loader)`ëŠ” ë¬¸ì„œ ë¡œë”©ì„ ìœ„í•œ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” `BaseLoader` ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œë‹¤.\n",
    "\n",
    "## ì¸í„°í˜ì´ìŠ¤\n",
    "- lazy_load : `ì§€ì—° ë¡œë”©(lazy loading)` ë°©ì‹ìœ¼ë¡œ ë¬¸ì„œë¥¼ í•˜ë‚˜ì”© ë¡œë“œí•œë‹¤. ì´ ë©”ì†Œë“œëŠ” í”„ë¡œë•ì…˜ ì½”ë“œì—ì„œ ì‚¬ìš©í•œë‹¤.\n",
    "- alazy_load : `lazy_load` ë©”ì†Œë“œì˜ ë¹„ë™ê¸°í™” ë²„ì „ì´ë‹¤. \n",
    "- load : `ì¦‰ì‹œ ë¡œë”©(eager loading)` ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ë¬¸ì„œë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•œë‹¤. ì´ ë©”ì†Œë“œëŠ” ê°œë°œ ì½”ë“œì—ì„œ ì‚¬ìš©í•œë‹¤.\n",
    "- aload : `load` ë©”ì†Œë“œì˜ ë¹„ë™ê¸°í™” ë²„ì „ì´ë‹¤.\n",
    "\n",
    "`load`ì™€ `aload` ë©”ì†Œë“œëŠ” ê°œë°œ ì‘ì—…ë§Œì„ ìœ„í•œ í¸ì˜ì„± ë°©ë²•ìœ¼ë¡œ, ë‚´ë¶€ì ìœ¼ë¡œ `list(self.lazy_load())`ë¥¼ í˜¸ì¶œí•œë‹¤.\n",
    "\n",
    "`alazy_load` ë©”ì†Œë“œëŠ” ë‚´ë¶€ì ìœ¼ë¡œ  `lazy_load` ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•œë‹¤. ë”°ë¼ì„œ ë¹„ë™ê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° `lazy_load` ë©”ì†Œë“œ êµ¬í˜„ì„ ì¬ì •ì˜í•˜ê³  `alazy_load` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.\n",
    "\n",
    "ë¬¸ì„œ ë¡œë”ë¥¼ êµ¬í˜„í•  ë•Œ `lazy_load` ë˜ëŠ” `lazy_load` ë©”ì„œë“œë¥¼ í†µí•´ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ ëª¨ë“  êµ¬ì„±ì€ `ì´ˆê¸°í™”(init)` ë©”ì†Œë“œë¥¼ í†µí•´ ì „ë‹¬ë˜ê³  ì´ëŠ” ë¬¸ì„œ ë¡œë”ê°€ ì¸ìŠ¤í„´ìŠ¤í™”ë˜ë©´ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë„ë¡ LangChainì´ ì„¤ê³„í•œ ê²ƒì´ë‹¤.\n",
    "\n",
    "## ì°¸ê³ \n",
    "- https://en.wikipedia.org/wiki/Lazy_loading\n",
    "- https://python.langchain.com/api_reference/core/document_loaders/langchain_core.document_loaders.base.BaseLoader.html\n",
    "- https://python.langchain.com/api_reference/_modules/langchain_core/document_loaders/base.html#BaseLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## êµ¬í˜„\n",
    "\n",
    "íŒŒì¼ì„ ë¡œë“œí•˜ê³  íŒŒì¼ì˜ ê° ì¤„ì—ì„œ ë¬¸ì„œë¥¼ ìƒì„±í•˜ëŠ” í‘œì¤€ ë¬¸ì„œ ë¡œë”ì˜ ì˜ˆë¥¼ ë§Œë“¤ì–´ë³´ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-core aiofiles ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncIterator, Iterator\n",
    "\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class CustomDocumentLoader(BaseLoader):\n",
    "    \"\"\"An example document loader that reads a file line by line.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        \"\"\"Initialize the loader with a file path.\n",
    "\n",
    "        Args:\n",
    "            file_path: The path to the file to load.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "    \n",
    "    # Does not take any arguments\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"A lazy loader that reads a file line by line.\n",
    "\n",
    "        When you're implementing lazy load methods, \n",
    "        you should use a generator to yield documents one by one\n",
    "        \"\"\"\n",
    "        with open(self.file_path, encoding=\"utf-8\") as f:\n",
    "            line_number = 0\n",
    "            for line in f:\n",
    "                yield Document(\n",
    "                    page_content=line,\n",
    "                    metadata={\n",
    "                        \"line_number\": line_number, \n",
    "                        \"source\": self.file_path\n",
    "                    }\n",
    "                )\n",
    "                line_number += 1\n",
    "    \n",
    "    # alazy_load is OPTIONAL.\n",
    "    # If you leave out the implementation, \n",
    "    # a default implementation which delegates to lazy_load will be used!\n",
    "    async def alazy_load(\n",
    "        self,\n",
    "    ) -> AsyncIterator[Document]:   # Does not take any arguments\n",
    "        \"\"\"An async lazy loader that reads a file line by line.\"\"\"\n",
    "        \n",
    "        # Requires aiofiles\n",
    "        # Install with `pip install aiofiles`\n",
    "        import aiofiles\n",
    "\n",
    "        async with aiofiles.open(self.file_path, encoding=\"utf-8\") as f:\n",
    "            line_number = 0\n",
    "            async for line in f:\n",
    "                yield Document(\n",
    "                    page_content=line,\n",
    "                    metadata={\n",
    "                        \"line_number\": line_number,\n",
    "                        \"source\": self.file_path,\n",
    "                    }\n",
    "                )\n",
    "                line_number += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./meow.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    quality_content = \"meow meowğŸ± \\n meow meowğŸ± \\n meowğŸ˜»ğŸ˜»\"\n",
    "    f.write(quality_content)\n",
    "\n",
    "loader = CustomDocumentLoader(\"./sample_data/meow.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content='meow meowğŸ± \n",
      "' metadata={'line_number': 0, 'source': './sample_data/meow.txt'}\n",
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content=' meow meowğŸ± \n",
      "' metadata={'line_number': 1, 'source': './sample_data/meow.txt'}\n",
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content=' meowğŸ˜»ğŸ˜»' metadata={'line_number': 2, 'source': './sample_data/meow.txt'}\n"
     ]
    }
   ],
   "source": [
    "## Test out the lazy load interface\n",
    "for doc in loader.lazy_load():\n",
    "    print()\n",
    "    print(type(doc))\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content='meow meowğŸ± \n",
      "' metadata={'line_number': 0, 'source': './sample_data/meow.txt'}\n",
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content=' meow meowğŸ± \n",
      "' metadata={'line_number': 1, 'source': './sample_data/meow.txt'}\n",
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content=' meowğŸ˜»ğŸ˜»' metadata={'line_number': 2, 'source': './sample_data/meow.txt'}\n"
     ]
    }
   ],
   "source": [
    "## Test out the async implementation\n",
    "async for doc in loader.alazy_load():\n",
    "    print()\n",
    "    print(type(doc))\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load ë©”ì†Œë“œëŠ” ì£¼í”¼í„° ë…¸íŠ¸ë¶ê³¼ ê°™ì€ ëŒ€í™”í˜• í™˜ê²½ì—ì„œ ìœ ìš©í•˜ì§€ë§Œ ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„°ì˜ ê²½ìš° ëª¨ë“  ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆë‹¤ê³  ê°€ì •í•˜ê¸° ë•Œë¬¸ì— í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'line_number': 0, 'source': './sample_data/meow.txt'}, page_content='meow meowğŸ± \\n'),\n",
       " Document(metadata={'line_number': 1, 'source': './sample_data/meow.txt'}, page_content=' meow meowğŸ± \\n'),\n",
       " Document(metadata={'line_number': 2, 'source': './sample_data/meow.txt'}, page_content=' meowğŸ˜»ğŸ˜»')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¡œë”©ê³¼ êµ¬ë¬¸ ë¶„ì„\n",
    "\n",
    "ë§ì€ `ë¬¸ì„œ ë¡œë”(document loader)`ì—ëŠ” íŒŒì¼ êµ¬ë¬¸ ë¶„ì„ì´ í¬í•¨ëœë‹¤. ì´ëŸ¬í•œ ë¡œë”ì˜ ì°¨ì´ì ì€ ì¼ë°˜ì ìœ¼ë¡œ `íŒŒì¼ì´ ë¡œë“œë˜ëŠ” ë°©ì‹(load logic)`ì´ ì•„ë‹ˆë¼ `íŒŒì¼ì´ êµ¬ë¬¸ ë¶„ì„ë˜ëŠ” ë°©ì‹(parsing logic)`ì—ì„œ ë¹„ë¡¯ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `open`ì„ ì‚¬ìš©í•˜ì—¬ PDF ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ì´ì§„ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ìˆì§€ë§Œ, ì´ì§„ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ë ¤ë©´ ë‹¤ë¥¸ êµ¬ë¬¸ ë¶„ì„ ë¡œì§ì´ í•„ìš”í•˜ë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ `êµ¬ë¬¸ ë¶„ì„ ë¡œì§(parsing logic)`ê³¼ `ë¡œë”© ë¡œì§(loading logic)`ì„ ë¶„ë¦¬í•˜ë©´ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë¡œë”©ë˜ì—ˆëŠ”ì§€ì— ê´€ê³„ì—†ì´ ì£¼ì–´ì§„ `êµ¬ë¬¸ ë¶„ì„ê¸°(parser)`ë¥¼ ë” ì‰½ê²Œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "## ì°¸ê³ \n",
    "- https://python.langchain.com/api_reference/_modules/langchain_community/document_loaders/pdf.html#PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseBlobParser\n",
    "\n",
    "`BaseBlobParser`ëŠ” `blob`ì„ ë°›ì•„ì„œ `Document` ê°ì²´ ëª©ë¡ì„ ì¶œë ¥í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ë‹¤. `blob`ì€ ë©”ëª¨ë¦¬ ë˜ëŠ” íŒŒì¼ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ í‘œí˜„í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.document_loaders import BaseBlobParser, Blob\n",
    "\n",
    "class MyParser(BaseBlobParser):\n",
    "    \"\"\"A simple parser that creates a document from each line.\"\"\"\n",
    "\n",
    "    def lazy_parse(self, blob: Blob) -> Iterator[Document]:\n",
    "        \"\"\"Parse a blob into a document line by line.\"\"\"\n",
    "        line_number = 0\n",
    "        with blob.as_bytes_io() as f:\n",
    "            for line in f:\n",
    "                line_number += 1\n",
    "                yield Document(\n",
    "                    page_content=line,\n",
    "                    metadata={\n",
    "                        \"line_number\": line_number,\n",
    "                        \"source\": blob.source,\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = Blob.from_path(\"./sample_data/meow.txt\")\n",
    "parser = MyParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'line_number': 1, 'source': './sample_data/meow.txt'}, page_content='meow meowğŸ± \\r\\n'),\n",
       " Document(metadata={'line_number': 2, 'source': './sample_data/meow.txt'}, page_content=' meow meowğŸ± \\r\\n'),\n",
       " Document(metadata={'line_number': 3, 'source': './sample_data/meow.txt'}, page_content=' meowğŸ˜»ğŸ˜»')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parser.lazy_parse(blob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜í•œ `blob API`ë¥¼ ì‚¬ìš©í•˜ë©´ íŒŒì¼ì—ì„œ ì½ì„ í•„ìš” ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ì½˜í…ì¸ ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'line_number': 1, 'source': None}, page_content='some data from memory\\n'),\n",
       " Document(metadata={'line_number': 2, 'source': None}, page_content='meow')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = Blob(data=b\"some data from memory\\nmeow\")\n",
    "list(parser.lazy_parse(blob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = Blob.from_path(\"./sample_data/meow.txt\", metadata={\"foo\": \"bar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'meow meow\\xf0\\x9f\\x90\\xb1 \\r\\n meow meow\\xf0\\x9f\\x90\\xb1 \\r\\n meow\\xf0\\x9f\\x98\\xbb\\xf0\\x9f\\x98\\xbb'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.as_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meow meowğŸ± \\n meow meowğŸ± \\n meowğŸ˜»ğŸ˜»'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x2373472d9d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.as_bytes_io()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'bar'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./sample_data/meow.txt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob ë¡œë”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`êµ¬ë¬¸ ë¶„ì„ê¸°(parser)`ëŠ” ì´ì§„ ë°ì´í„°ë¥¼ ë¬¸ì„œë¡œ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë° í•„ìš”í•œ ë¡œì§ì„ ìº¡ìŠí™”í•˜ëŠ” ë°˜ë©´, `Blob ë¡œë”`ëŠ” ì£¼ì–´ì§„ ì €ì¥ ìœ„ì¹˜ì—ì„œ `Blob`ì„ ë¡œë“œí•˜ëŠ” ë° í•„ìš”í•œ ë¡œì§ì„ ìº¡ìŠí™”í•œë‹¤.\n",
    "\n",
    "í˜„ì¬ LangChainì€ 0.3 ë²„ì „ ê¸°ì¤€ìœ¼ë¡œ `FileSystemBlobLoader`ë§Œ ì§€ì›í•œë‹¤. `FileSystemBlobLoader`ë¥¼ ì‚¬ìš©í•˜ì—¬ `Blob`ì„ ë¡œë“œí•œ ë‹¤ìŒ êµ¬ë¬¸ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ `Blob`ì„ êµ¬ë¬¸ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## ì°¸ê³ \n",
    "- https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.blob_loaders.file_system.FileSystemBlobLoader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.blob_loaders import FileSystemBlobLoader\n",
    "\n",
    "blob_loader = FileSystemBlobLoader(path=\"./sample_data\", glob=\"*.txt\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 938.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='meow meowğŸ± \n",
      "' metadata={'line_number': 1, 'source': 'sample_data\\\\meow.txt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parser = MyParser()\n",
    "for blob in blob_loader.yield_blobs():  # Blob ë¡œë“œ\n",
    "    for doc in parser.lazy_parse(blob):       # Blob íŒŒì‹±\n",
    "        print(doc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Loader\n",
    "LangChainì€ `GenericLoader` ì¶”ìƒí™”ë¥¼ í†µí•´ `BaseBlobParser`ì™€ `BlobLoader`ë¥¼ í•¨ê»˜ êµ¬ì„±í•œë‹¤.\n",
    "\n",
    "`GenericLoader`ëŠ” ê¸°ì¡´ `BlobLoader` êµ¬í˜„ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í‘œì¤€í™”ëœ í´ë˜ìŠ¤ ë°©ë²•ì„ ì œê³µí•œë‹¤. í˜„ì¬ëŠ” `FileSystemBlobLoader`ë§Œ ì§€ì›ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 651.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='meow meowğŸ± \n",
      "' metadata={'line_number': 1, 'source': 'sample_data\\\\meow.txt'}\n",
      "page_content=' meow meowğŸ± \n",
      "' metadata={'line_number': 2, 'source': 'sample_data\\\\meow.txt'}\n",
      "page_content=' meowğŸ˜»ğŸ˜»' metadata={'line_number': 3, 'source': 'sample_data\\\\meow.txt'}\n",
      "... output truncated for demo purposes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    path=\"./sample_data\",\n",
    "    glob=\"*.txt\",\n",
    "    show_progress=True,\n",
    "    parser=MyParser()\n",
    ")\n",
    "\n",
    "for idx, doc in enumerate(loader.lazy_load()):\n",
    "    if idx < 5:\n",
    "        print(doc)\n",
    "\n",
    "print(\"... output truncated for demo purposes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì»¤ìŠ¤í…€ Generic Loader\n",
    "\n",
    "í´ë˜ìŠ¤ë¥¼ ë§Œë“œëŠ” ê²ƒì„ ì •ë§ ì¢‹ì•„í•œë‹¤ë©´ í•˜ìœ„ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ì–´ì„œ ë¡œì§ì„ ìº¡ìŠí™”í•˜ë©´ ëœë‹¤. ì´ í´ë˜ìŠ¤ë¥¼ í•˜ìœ„ í´ë˜ìŠ¤ë¡œ ì‚¬ìš©í•˜ë©´ ê¸°ì¡´ ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class MyCustomLoader(GenericLoader):\n",
    "    @staticmethod\n",
    "    def get_parser(**kwargs: Any) -> BaseBlobParser:\n",
    "        \"\"\"Override this method to associate a default parser with the class.\"\"\"\n",
    "        return MyParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1000.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='meow meowğŸ± \n",
      "' metadata={'line_number': 1, 'source': 'sample_data\\\\meow.txt'}\n",
      "page_content=' meow meowğŸ± \n",
      "' metadata={'line_number': 2, 'source': 'sample_data\\\\meow.txt'}\n",
      "page_content=' meowğŸ˜»ğŸ˜»' metadata={'line_number': 3, 'source': 'sample_data\\\\meow.txt'}\n",
      "... output truncated for demo purposes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = MyCustomLoader.from_filesystem(\n",
    "    path=\"./sample_data/\", \n",
    "    glob=\"*.txt\", \n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "for idx, doc in enumerate(loader.lazy_load()):\n",
    "    if idx < 5:\n",
    "        print(doc)\n",
    "\n",
    "print(\"... output truncated for demo purposes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "how-to-guides-MvvQz3WI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
